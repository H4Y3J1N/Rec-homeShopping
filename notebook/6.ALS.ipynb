{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wikid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from scipy.sparse import csr_matrix\n",
    "import implicit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "import pickle\n",
    "from dataLoad import trainValidLoad\n",
    "from metric import ndcg_calculator, hit_at_k\n",
    "\n",
    "path= \"../dataset/\"\n",
    "train, train_valid, sample_sumbission = trainValidLoad(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_item_maps(df):\n",
    "    ALL_USERS = df[\"user\"].unique().tolist()\n",
    "    ALL_ITEMS = df[\"item_id\"].unique().tolist()\n",
    "\n",
    "    user_ids = dict(list(enumerate(ALL_USERS)))\n",
    "    item_ids = dict(list(enumerate(ALL_ITEMS)))\n",
    "\n",
    "    user_map = {u: uidx for uidx, u in user_ids.items()}\n",
    "    item_map = {i: iidx for iidx, i in item_ids.items()}\n",
    "\n",
    "    df[\"user\"] = df[\"user\"].map(user_map)\n",
    "    df[\"item_id\"] = df[\"item_id\"].map(item_map)\n",
    "    return ALL_USERS, ALL_ITEMS, user_ids, item_ids, user_map, item_map\n",
    "\n",
    "def make_csr_matrix(df):\n",
    "    row = df[\"user\"].values\n",
    "    col = df[\"item_id\"].values\n",
    "    data = np.ones(df.shape[0])\n",
    "    csr_train = csr_matrix((data, (row, col)), shape=(len(ALL_USERS), len(ALL_ITEMS)))\n",
    "    return csr_train\n",
    "\n",
    "\n",
    "def train_mf(csr_train, factors=200, iterations=3, regularization=0.05, show_progress=True):\n",
    "    model = implicit.als.AlternatingLeastSquares(factors=factors, \n",
    "                                                 iterations=iterations, \n",
    "                                                 regularization=regularization, \n",
    "                                                 random_state=42)\n",
    "    model.fit(csr_train, show_progress=show_progress)\n",
    "    return model\n",
    "\n",
    "\n",
    "def real_submit(model, csr_train, sample_sumbission):  \n",
    "    preds = []\n",
    "    batch_size = 2000\n",
    "    to_generate = np.arange(len(ALL_USERS))\n",
    "    pred_df = []\n",
    "    for startidx in range(0, len(to_generate), batch_size):\n",
    "        batch = to_generate[startidx : startidx + batch_size]\n",
    "        ids, scores = model.recommend(batch, csr_train[batch], N=10, filter_already_liked_items=False)\n",
    "        for i, user in enumerate(batch):\n",
    "            user = user_ids[user]\n",
    "            user_items = ids[i]\n",
    "            items_ids = [item_ids[item_id] for item_id in user_items] \n",
    "            pred_df.append({\"user\":user,\"predicted_list\":items_ids})\n",
    "    pred_dfs = pd.DataFrame(pred_df)    \n",
    "    sample_sumbission = sample_sumbission.merge(pred_dfs, on=\"user\")\n",
    "    return sample_sumbission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [03:28<00:00, 69.52s/it]\n"
     ]
    }
   ],
   "source": [
    "ALL_USERS, ALL_ITEMS, user_ids, item_ids, user_map, item_map = user_item_maps(train)\n",
    "mf_csr = make_csr_matrix(train)\n",
    "mf_model = train_mf(mf_csr)\n",
    "mf_preds = real_submit(mf_model, mf_csr, sample_sumbission)\n",
    "\n",
    "#65m 57.3s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance\n",
      "nDCG@10(mf_ALS): 0.0399\n",
      "CPU times: total: 11.5 s\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mf_ndcg = ndcg_calculator(train_valid, mf_preds, 10)\n",
    "\n",
    "print(\"performance\")\n",
    "print(f\"nDCG@10(mf_ALS): {mf_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance\n",
      "hit@10(mf_ALS): 0.0279\n",
      "CPU times: total: 5.67 s\n",
      "Wall time: 5.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mf_hit = hit_at_k(train_valid, mf_preds, 10)\n",
    "\n",
    "print(\"performance\")\n",
    "print(f\"hit@10(mf_ALS): {mf_hit:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance\n",
      "hit@1(mf_ALS): 0.0279\n",
      "CPU times: total: 5.47 s\n",
      "Wall time: 5.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mf_hit = hit_at_k(train_valid, mf_preds, 1)\n",
    "\n",
    "print(\"performance\")\n",
    "print(f\"hit@1(mf_ALS): {mf_hit:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model & factor & ect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(mf_model, open(\"../output/als_model.pkl\", \"wb\"))\n",
    "sparse.save_npz(\"../output/als_csr.npz\", mf_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user factor 추출 \n",
    "k=200\n",
    "user_factors = pd.DataFrame(mf_model.user_factors)\n",
    "user_factors.columns = [f\"user_{i}\" for i in range(k)]\n",
    "user_factors.index = user_factors.index.map(user_ids)\n",
    "user_factors = user_factors.reset_index().rename(columns={\"index\":\"user\"})\n",
    "user_factors.to_parquet(\"../output/user_factor_als.parquet\")\n",
    "\n",
    "\n",
    "# item factor 추출\n",
    "item_factors = pd.DataFrame(mf_model.item_factors)\n",
    "item_factors.columns = [f\"item_id_{i}\" for i in range(k)]\n",
    "item_factors.index = item_factors.index.map(item_ids)\n",
    "item_factors = item_factors.reset_index().rename(columns={\"index\":\"item_id\"})\n",
    "\n",
    "item_factors.to_parquet(\"../output/item_factor_als.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a31a978b9b36123e657517a00f2bc515935c5b3db5200b3f6166774c20a94c04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
