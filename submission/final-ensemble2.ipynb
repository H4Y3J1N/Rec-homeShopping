{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-02-07T19:23:12.779807Z","iopub.status.busy":"2023-02-07T19:23:12.779297Z","iopub.status.idle":"2023-02-07T19:23:12.786139Z","shell.execute_reply":"2023-02-07T19:23:12.784952Z","shell.execute_reply.started":"2023-02-07T19:23:12.779763Z"},"trusted":true},"outputs":[],"source":["import sys\n","sys.path.append(\"../src\")\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import pickle\n","import lightgbm\n","import pickle\n","from dataLoad import testLoad\n","from metric import ndcg_calculator, hit_at_k\n","\n","path= \"../dataset/\"\n","test, final_sumbission, test_user_label = testLoad(path)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-02-07T19:23:16.058436Z","iopub.status.busy":"2023-02-07T19:23:16.057587Z","iopub.status.idle":"2023-02-07T19:23:19.271784Z","shell.execute_reply":"2023-02-07T19:23:19.270824Z","shell.execute_reply.started":"2023-02-07T19:23:16.058397Z"},"trusted":true},"outputs":[],"source":["test = test.sort_values(by =\"timestamp\", ascending = True)\\\n","        .reset_index(drop=True).drop(columns=[\"timestamp\",\"click_count_normalized\",\"user_click_count_normalized\"])"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-02-07T19:23:19.273678Z","iopub.status.busy":"2023-02-07T19:23:19.273117Z","iopub.status.idle":"2023-02-07T19:23:28.588544Z","shell.execute_reply":"2023-02-07T19:23:28.587549Z","shell.execute_reply.started":"2023-02-07T19:23:19.273629Z"},"trusted":true},"outputs":[],"source":["with open(\"../output/first_batch2000lgbm_model.pkl\", 'rb') as f:\n","    first_batch2000lgbm_model = pickle.load(f)"]},{"cell_type":"markdown","metadata":{},"source":["--- LgbmRanker + ALS + MP + Word2Vec Ensemble      \n","      \n","feature :      \n","*    datset - basic features from featureExtract      \n","*    Mp - general most popular feature      \n","*    ALS - user / item factor      \n","<!-- *    Word2Vec - item segmentation       -->\n","      \n","candidate :      \n","*    Mp  - general/recent weeks Most popular      \n","<!-- *    Word2Vec - similar items       --> "]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-02-07T19:23:28.591961Z","iopub.status.busy":"2023-02-07T19:23:28.591217Z","iopub.status.idle":"2023-02-07T19:23:28.596518Z","shell.execute_reply":"2023-02-07T19:23:28.595679Z","shell.execute_reply.started":"2023-02-07T19:23:28.591919Z"},"trusted":true},"outputs":[],"source":["# # load features\n","# basic_7_feature = pd.read_parquet(\"../output/basic_7_feature.parquet\")\n","general_MP_feature = pd.read_parquet(\"../output/general_MP_feature.parquet\")\n","user_factor_als = pd.read_parquet(\"../output/user_factor_als.parquet\")\n","item_factor_als = pd.read_parquet(\"../output/item_factor_als.parquet\")\n","\n","# # load candidates\n","# recent30days_MP_candidate = pd.read_parquet(\"../output/recent30days_MP_candidate.parquet\")\n","# popular_items_cand = pd.read_parquet(\"../output/popular_items_cand.parquet\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-02-07T19:23:28.599569Z","iopub.status.busy":"2023-02-07T19:23:28.598796Z","iopub.status.idle":"2023-02-07T19:23:57.345903Z","shell.execute_reply":"2023-02-07T19:23:57.343534Z","shell.execute_reply.started":"2023-02-07T19:23:28.599529Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cand 데이터 수: 119636648\n","cand nunique:  177\n"]}],"source":["# candidate_1 = recent30days_MP_candidate\n","# candidate_2 = popular_items_cand\n","# candidate = [candidate_1, candidate_2]\n","# cand = pd.concat(candidate)\n","# cand.drop_duplicates(subset=['user','item_id'],inplace=True)\n","\n","# print('cand 데이터 수:',len(cand))\n","# print('cand nunique: ', cand.item_id.nunique())"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:23:57.347054Z","iopub.status.idle":"2023-02-07T19:23:57.348147Z","shell.execute_reply":"2023-02-07T19:23:57.347930Z","shell.execute_reply.started":"2023-02-07T19:23:57.347905Z"},"trusted":true},"outputs":[],"source":["# add feature \n","candidate = pd.merge(test, general_MP_feature, how='left', on='item_id')\n","candidate = pd.merge(candidate, item_factor_als, how=\"left\", on=\"item_id\")\n","candidate = pd.merge(candidate, user_factor_als, how=\"left\", on=\"user\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-07T19:24:55.673077Z","iopub.status.busy":"2023-02-07T19:24:55.672589Z","iopub.status.idle":"2023-02-07T19:24:59.668722Z","shell.execute_reply":"2023-02-07T19:24:59.667551Z","shell.execute_reply.started":"2023-02-07T19:24:55.673035Z"},"trusted":true},"outputs":[],"source":["candidate = candidate.fillna(0).astype(int)  # astype int, fillna"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''\n","OOM issue - 대안으로 candidate를 포기하고, feature 만 진행합니다.\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-07T19:24:59.687632Z","iopub.status.busy":"2023-02-07T19:24:59.686844Z","iopub.status.idle":"2023-02-07T19:24:59.706220Z","shell.execute_reply":"2023-02-07T19:24:59.704332Z","shell.execute_reply.started":"2023-02-07T19:24:59.687591Z"},"trusted":true},"outputs":[],"source":["def make_label(train_valid):\n","    label_df = train_valid[[\"user\",\"item_id\"]]\n","    label_df.drop_duplicates(subset=[\"user\",\"item_id\"],inplace=True)\n","    label_df[\"click_num\"] = 1\n","    return label_df\n","\n","def label_create(train, label_df):\n","    train = pd.merge(train, label_df, how=\"left\", on=[\"user\",\"item_id\"])\n","    train[\"click_num\"] = train[\"click_num\"].fillna(0)\n","    return train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-07T19:24:59.709456Z","iopub.status.busy":"2023-02-07T19:24:59.708801Z","iopub.status.idle":"2023-02-07T19:25:53.745253Z","shell.execute_reply":"2023-02-07T19:25:53.744156Z","shell.execute_reply.started":"2023-02-07T19:24:59.709406Z"},"trusted":true},"outputs":[],"source":["label_df = make_label(test_user_label)\n","candidate_add_features = label_create(candidate, label_df)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["'''\n","OOM issue로 인해 여기까지 완성한 data import 후 다음 단계로 진행합니다\n","'''\n","test_candidate_add_features = pd.read_parquet(\"../output/test_candidate_add_features.parquet\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:23:57.360521Z","iopub.status.idle":"2023-02-07T19:23:57.360950Z","shell.execute_reply":"2023-02-07T19:23:57.360773Z","shell.execute_reply.started":"2023-02-07T19:23:57.360752Z"},"trusted":true},"outputs":[],"source":["# print(candidate_add_features[candidate_add_features[\"click_num\"]==1].count()) # 46771\n","# print(candidate_add_features[candidate_add_features[\"click_num\"]==0].count()) # 102260423"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-02-07T19:25:53.763981Z","iopub.status.busy":"2023-02-07T19:25:53.763594Z","iopub.status.idle":"2023-02-07T19:25:53.778805Z","shell.execute_reply":"2023-02-07T19:25:53.777619Z","shell.execute_reply.started":"2023-02-07T19:25:53.763946Z"},"trusted":true},"outputs":[],"source":["def lgbm_preprocess(train):\n","    X_train = train.drop(columns=[\"click_num\"])\n","    y_train = train[\"click_num\"]\n","#     group_dict = train.groupby(\"user\")[\"user\"].count().to_dict()\n","    item_idx = X_train[\"item_id\"].copy()\n","    user_idx = X_train[\"user\"].copy()\n","    del X_train[\"item_id\"], X_train[\"user\"]\n","    return X_train, y_train, item_idx, user_idx\n","\n","def make_groups(X_train):\n","    group_dict = []\n","    batchsize = len(X_train)\n","    while True:\n","        if batchsize >= 2000:\n","            group_dict.append(2000)\n","            batchsize = batchsize - 2000\n","        else:\n","            group_dict.append(batchsize)\n","            break\n","            \n","def train_LgbmRanker_batch(X_train, y_train, model_params, batch_size):\n","    model = first_batch2000lgbm_model\n","    num_batches = X_train.shape[0] // batch_size\n","    for i in tqdm(range(0, X_train.shape[0], batch_size), total=num_batches):\n","        X_batch = X_train[i:i + batch_size]\n","        y_batch = y_train[i:i + batch_size]\n","        group_dict = []\n","        batchsize = len(X_batch)\n","        while batchsize !=0 :\n","            if batchsize >= 1000:\n","                group_dict.append(1000)\n","                batchsize = batchsize - 1000\n","            else:\n","                group_dict.append(batchsize)\n","                batchsize -= batchsize \n","        model.fit(\n","        X=X_batch,\n","        y=y_batch,\n","        group=group_dict,\n","        ) \n","    feature_importances_df = pd.DataFrame(dict(zip(X_train.columns, model.feature_importances_)), index=[\"feature_importances\"]).T\n","    return model, feature_importances_df\n","\n","    \n","def valid_evaluation(X_train, train_valid, sample_sumbission, model, feature_importances_df, item_idx, user_idx): \n","    print(feature_importances_df)\n","    pred = model.predict(X_train)\n","    X_train[\"pred\"] = pred\n","    X_train[\"item_id\"] = item_idx\n","    X_train[\"user\"] = user_idx\n","    \n","    print(\"performance\")\n","    # each user pred 10 items\n","    lgbm_sub_df = X_train.sort_values(by=\"pred\", ascending=False).groupby(\"user\").head(10)\n","    lgbm_user_items_dict = lgbm_sub_df.groupby(\"user\")[\"item_id\"].unique().to_dict()\n","    sample_sumbission[\"predicted_list\"] = sample_sumbission[\"user\"].apply(lambda x: lgbm_user_items_dict.get(x, []))\n","\n","    # print(\"lgbm ndcg:\", ndcg_calculator(sample_sumbission, train_valid, 10))\n","        \n","    return X_train, sample_sumbission"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-02-07T19:25:53.782197Z","iopub.status.busy":"2023-02-07T19:25:53.781714Z","iopub.status.idle":"2023-02-07T19:25:53.936917Z","shell.execute_reply":"2023-02-07T19:25:53.935516Z","shell.execute_reply.started":"2023-02-07T19:25:53.782151Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import gc\n","gc.collect()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.status.busy":"2023-02-07T19:23:57.369625Z","iopub.status.idle":"2023-02-07T19:23:57.370016Z","shell.execute_reply":"2023-02-07T19:23:57.369850Z","shell.execute_reply.started":"2023-02-07T19:23:57.369832Z"},"trusted":true},"outputs":[],"source":["model_params={\"num_leaves\":150 ,\"learning_rate\":0.005,\"n_estimators\":35}"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-02-07T19:25:53.940227Z","iopub.status.busy":"2023-02-07T19:25:53.939431Z","iopub.status.idle":"2023-02-07T19:26:00.578676Z","shell.execute_reply":"2023-02-07T19:26:00.577032Z","shell.execute_reply.started":"2023-02-07T19:25:53.940176Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["703it [03:55,  2.98it/s]                         \n"]},{"name":"stdout","output_type":"stream","text":["             feature_importances\n","day_of_week             0.000000\n","days                    0.000000\n","hour                   27.127226\n","weeks                   0.000000\n","cumcount             1144.737772\n","...                          ...\n","user_45                 0.000000\n","user_46                 0.000000\n","user_47                 0.000000\n","user_48                 0.000000\n","user_49                 0.000000\n","\n","[109 rows x 1 columns]\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\wikid\\AppData\\Local\\Temp\\ipykernel_15652\\310903693.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train[\"pred\"] = pred\n","C:\\Users\\wikid\\AppData\\Local\\Temp\\ipykernel_15652\\310903693.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train[\"item_id\"] = item_idx\n","C:\\Users\\wikid\\AppData\\Local\\Temp\\ipykernel_15652\\310903693.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X_train[\"user\"] = user_idx\n"]},{"name":"stdout","output_type":"stream","text":["performance\n"]}],"source":["X_train, y_train, item_idx, user_idx = lgbm_preprocess(test_candidate_add_features)\n","model, feature_importances_df = train_LgbmRanker_batch(X_train, y_train, model_params, 10000)\n","\n","X_train, final_sumbission = \\\n","     valid_evaluation(X_train, test_user_label, final_sumbission, model, feature_importances_df, item_idx, user_idx)"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["def _ndcg_calculator(gt, rec, idcg):\n","    if not isinstance(rec, list):\n","        rec = [rec]\n","    dcg = 0.0\n","    if rec in gt:\n","            dcg = 1.0 / np.log(2)\n","    return dcg / idcg\n","\n","def ndcg_calculator(answer, submission, n=10):\n","    idcg = sum((1.0 / np.log(i + 1) for i in range(1, n + 1)))\n","    assert (answer.user != submission.user).sum() == 0\n","    ndcg_list = []\n","    for (_, row_answer), (_, row_submit) in zip(answer.iterrows(), submission.iterrows()):\n","        ndcg_list.append(_ndcg_calculator(row_answer.item_id, row_submit.predicted_list, idcg))\n","    ndcg_score = sum(ndcg_list) / len(answer)\n","    return ndcg_score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def _ndcg_calculator(gt, rec, idcg):\n","    if not isinstance(rec, list):\n","        rec = [rec]\n","    dcg = 0.0\n","    for i, r in enumerate(rec):\n","        if r in set(gt):\n","            dcg += 1.0 / np.log(i + 2)\n","    return dcg / idcg\n","\n","def ndcg_calculator(answer, submission, n=10):\n","    idcg = sum((1.0 / np.log(i + 1) for i in range(1, n + 1)))\n","    assert (answer.user != submission.user).sum() == 0\n","    ndcg_list = []\n","    for (_, row_answer), (_, row_submit) in zip(answer.iterrows(), submission.iterrows()):\n","        ndcg_list.append(_ndcg_calculator(row_answer.item_id, row_submit.predicted_list, idcg))\n","    ndcg_score = sum(ndcg_list) / len(answer)\n","    return ndcg_score"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>predicted_list</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[396362, 888904, 228561, 18748, 99247, 784458,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>[148090, 293913, 839005, 293981, 597318, 20430...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>[832922, 247703, 267761, 710805, 41459, 716642...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>[544492, 614476, 949905, 560874, 126927, 96282...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>[641013, 577279, 168299, 486989, 895860, 73144...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>587481</th>\n","      <td>829386</td>\n","      <td>[813829, 810147, 554650, 130000, 893014]</td>\n","    </tr>\n","    <tr>\n","      <th>587482</th>\n","      <td>829390</td>\n","      <td>[47147, 945164, 712124, 310178, 866254, 851941...</td>\n","    </tr>\n","    <tr>\n","      <th>587483</th>\n","      <td>829393</td>\n","      <td>[115233, 492271]</td>\n","    </tr>\n","    <tr>\n","      <th>587484</th>\n","      <td>829397</td>\n","      <td>[503200, 517483]</td>\n","    </tr>\n","    <tr>\n","      <th>587485</th>\n","      <td>829403</td>\n","      <td>[335217, 628847, 167515, 263005, 183824, 56704...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>587486 rows × 2 columns</p>\n","</div>"],"text/plain":["          user                                     predicted_list\n","0            0  [396362, 888904, 228561, 18748, 99247, 784458,...\n","1            1  [148090, 293913, 839005, 293981, 597318, 20430...\n","2            2  [832922, 247703, 267761, 710805, 41459, 716642...\n","3            3  [544492, 614476, 949905, 560874, 126927, 96282...\n","4            4  [641013, 577279, 168299, 486989, 895860, 73144...\n","...        ...                                                ...\n","587481  829386           [813829, 810147, 554650, 130000, 893014]\n","587482  829390  [47147, 945164, 712124, 310178, 866254, 851941...\n","587483  829393                                   [115233, 492271]\n","587484  829397                                   [503200, 517483]\n","587485  829403  [335217, 628847, 167515, 263005, 183824, 56704...\n","\n","[587486 rows x 2 columns]"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["final_sumbission"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["performance\n","nDCG@10(mf_ALS): 0.0160\n","CPU times: total: 3min 1s\n","Wall time: 3min 1s\n"]}],"source":["%%time\n","mf_ndcg = ndcg_calculator(test_user_label, final_sumbission, 10)\n","\n","print(\"performance\")\n","print(f\"nDCG@10(mf_ALS): {mf_ndcg:.4f}\")"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["performance\n","hit@10(mf_ALS): 0.0270\n","CPU times: total: 1min 30s\n","Wall time: 1min 31s\n"]}],"source":["%%time\n","mf_hit = hit_at_k(test_user_label, final_sumbission, 10)\n","\n","print(\"performance\")\n","print(f\"hit@10(mf_ALS): {mf_hit:.4f}\")"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["performance\n","hit@1(mf_ALS): 0.0270\n","CPU times: total: 1min 31s\n","Wall time: 1min 31s\n"]}],"source":["%%time\n","mf_hit = hit_at_k(test_user_label, final_sumbission, 1)\n","\n","print(\"performance\")\n","print(f\"hit@1(mf_ALS): {mf_hit:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# X_train.to_parquet(\"../output/batch1000_lgbm_X_train.parquet\", index=False)\n","# pickle.dump(model, open(\"../output/batch1000_lgbm_model.pkl\", \"wb\"))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"vscode":{"interpreter":{"hash":"a31a978b9b36123e657517a00f2bc515935c5b3db5200b3f6166774c20a94c04"}}},"nbformat":4,"nbformat_minor":4}
